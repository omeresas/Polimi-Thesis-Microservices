% A LaTeX template for MSc Thesis submissions to 
% Politecnico di Milano (PoliMi) - School of Industrial and Information Engineering
%
% S. Bonetti, A. Gruttadauria, G. Mescolini, A. Zingaro
% e-mail: template-tesi-ingind@polimi.it
%
% Last Revision: October 2021
%
% Copyright 2021 Politecnico di Milano, Italy. NC-BY

\documentclass{Configuration_Files/PoliMi3i_thesis}

%------------------------------------------------------------------------------
%	REQUIRED PACKAGES AND  CONFIGURATIONS
%------------------------------------------------------------------------------

% CONFIGURATIONS
\usepackage{parskip} % For paragraph layout
\usepackage{setspace} % For using single or double spacing
\usepackage{emptypage} % To insert empty pages
\usepackage{multicol} % To write in multiple columns (executive summary)
\setlength\columnsep{15pt} % Column separation in executive summary
\setlength\parindent{0pt} % Indentation
\raggedbottom  

% PACKAGES FOR TITLES
\usepackage{titlesec}
% \titlespacing{\section}{left spacing}{before spacing}{after spacing}
\titlespacing{\section}{0pt}{3.3ex}{2ex}
\titlespacing{\subsection}{0pt}{3.3ex}{1.65ex}
\titlespacing{\subsubsection}{0pt}{3.3ex}{1ex}
\usepackage{color}

% PACKAGES FOR LANGUAGE AND FONT
\usepackage[english]{babel} % The document is in English  
\usepackage[utf8]{inputenc} % UTF8 encoding
\usepackage[T1]{fontenc} % Font encoding
\usepackage[11pt]{moresize} % Big fonts

% PACKAGES FOR IMAGES
\usepackage{graphicx}
\usepackage{transparent} % Enables transparent images
\usepackage{eso-pic} % For the background picture on the title page
\usepackage{subfig} % Numbered and caption subfigures using \subfloat.
\usepackage{tikz} % A package for high-quality hand-made figures.
\usetikzlibrary{}
\graphicspath{{./Images/}} % Directory of the images
\usepackage{caption} % Coloured captions
\usepackage{xcolor} % Coloured captions
\usepackage{amsthm,thmtools,xcolor} % Coloured "Theorem"
\usepackage{float}

% STANDARD MATH PACKAGES
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage[overload]{empheq} % For braced-style systems of equations.
\usepackage{fix-cm} % To override original LaTeX restrictions on sizes

% PACKAGES FOR TABLES
\usepackage{tabularx}
\usepackage{longtable} % Tables that can span several pages
\usepackage{colortbl}

% PACKAGES FOR ALGORITHMS (PSEUDO-CODE)
\usepackage{algorithm}
\usepackage{algorithmic}

% PACKAGES FOR REFERENCES & BIBLIOGRAPHY
\usepackage[colorlinks=true,linkcolor=black,anchorcolor=black,citecolor=black,filecolor=black,menucolor=black,runcolor=black,urlcolor=black]{hyperref} % Adds clickable links at references
\usepackage{cleveref}
% I CHANGED BELOW TWO LINES
\bibliographystyle{unsrtnat}
\usepackage[numbers,sort&compress]{natbib}

% OTHER PACKAGES
\usepackage{pdfpages} % To include a pdf file
\usepackage{afterpage}
\usepackage{lipsum} % DUMMY PACKAGE
\usepackage{fancyhdr} % For the headers
\fancyhf{}

% Input of configuration file. Do not change config.tex file unless you really know what you are doing. 
\input{Configuration_Files/config}

%----------------------------------------------------------------------------
%	NEW COMMANDS DEFINED
%----------------------------------------------------------------------------

% EXAMPLES OF NEW COMMANDS
\newcommand{\bea}{\begin{eqnarray}} % Shortcut for equation arrays
\newcommand{\eea}{\end{eqnarray}}
\newcommand{\e}[1]{\times 10^{#1}}  % Powers of 10 notation

%----------------------------------------------------------------------------
%	ADD YOUR PACKAGES (be careful of package interaction)
%----------------------------------------------------------------------------

%----------------------------------------------------------------------------
%	ADD YOUR DEFINITIONS AND COMMANDS (be careful of existing commands)
%----------------------------------------------------------------------------

%----------------------------------------------------------------------------
%	BEGIN OF YOUR DOCUMENT
%----------------------------------------------------------------------------

\begin{document}

\fancypagestyle{plain}{%
\fancyhf{} % Clear all header and footer fields
\fancyhead[RO,RE]{\thepage} %RO=right odd, RE=right even
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}}

%----------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------

\pagestyle{empty} % No page numbers
\frontmatter % Use roman page numbering style (i, ii, iii, iv...) for the preamble pages

\puttitle{
	title=Title Related to Microservices, % Title of the thesis
	name=Ömer Esas, % Author Name and Surname
	course=Computer Science and Engineering - Ingegneria Informatica, % Study Programme (in Italian)
	ID  = 917254,  % Student ID number (numero di matricola)
	advisor= Prof. Elisabetta Di Nitto, % Supervisor name
	coadvisor={Name Surname, Name Surname}, % Co-Supervisor name, remove this line if there is none
	academicyear={2021-22},  % Academic Year
} % These info will be put into your Title page 

%----------------------------------------------------------------------------
%	PREAMBLE PAGES: ABSTRACT (inglese e italiano), EXECUTIVE SUMMARY
%----------------------------------------------------------------------------
\startpreamble
\setcounter{page}{1} % Set page counter to 1

% ABSTRACT IN ENGLISH
\chapter*{Abstract} 
Here goes the Abstract in English of your thesis followed by a list of keywords.
\\
\\
\textbf{Keywords:} here, the keywords, of your thesis % Keywords

% ABSTRACT IN ITALIAN
\chapter*{Abstract in lingua italiana}
Qui va l'Abstract in lingua italiana della tesi seguito dalla lista di parole chiave.
\\
\\
\textbf{Parole chiave:} qui, vanno, le parole chiave, della tesi % Keywords (italian)

%----------------------------------------------------------------------------
%	LIST OF CONTENTS/FIGURES/TABLES/SYMBOLS
%----------------------------------------------------------------------------

% TABLE OF CONTENTS
\thispagestyle{empty}
\tableofcontents % Table of contents 
\thispagestyle{empty}
\cleardoublepage

%-------------------------------------------------------------------------
%	THESIS MAIN TEXT
%-------------------------------------------------------------------------
% In the main text of your thesis you can write the chapters in two different ways:
%
%(1) As presented in this template you can write:
%    \chapter{Title of the chapter}
%    *body of the chapter*
%
%(2) You can write your chapter in a separated .tex file and then include it in the main file with the following command:
%    \chapter{Title of the chapter}
%    \input{chapter_file.tex}
%
% Especially for long thesis, we recommend you the second option.

\addtocontents{toc}{\vspace{2em}} % Add a gap in the Contents, for aesthetics
\mainmatter % Begin numeric (1,2,3...) page numbering

% --------------------------------------------------------------------------
% NUMBERED CHAPTERS % Regular chapters following
% --------------------------------------------------------------------------
\chapter{Introduction}

\chapter{State of the Art}
\label{ch:art}%

\section{Microservice Architecture}
\label{sec:ms_arch}

Although the microservice architecture style has already been a de-facto standard for some large tech companies, and is being embraced by numerous firms in the industry, because of the novelty of the architecture, not all developers and architects in the tech industry and researchers in the academia are aware of what it means and which paradigms it advertises.
Microservice architecture is, not in the least meaning of the word, vastly different from the traditional way of building a web application, namely the monolithic architecture.
Hence, it is a valuable effort to define microservice architecture, what it is about and describe features and trends from which this rather unorthodox architecture emerged.
\\
Most importantly, microservice architecture is, as the name suggests, a software architecture.
There are numerous and slightly different definitions based on the particular discipline of software engineering for what a software architecture is.
However, a very simple yet powerful definition is, a (software) architecture is a representation of significant design decisions that shape a system, where significant is measured by the cost of change \cite{booch}. 
In the case for microservice architecture, the most signification design decision is, splitting the system into small, autonomous services that work together.
Focusing on each element of this design decision will bring about more clarity about the architecture.
\\
First, the microservice architecture divide the system into parts, as other architectural styles do, based on various points of views of the system.
Single Responsibility Principle, one of the famous SOLID principles of software engineering, promotes the idea that every module, class or a function in a computer program should have responsibility over a single part of that program's functionality, and it should encapsulate that part \cite{srp}.
The microservice architecture takes that idea to the extreme and encourages developing independent microservices that tackles just one business functionality.
Unlike a monolithic application, the system is not layered as database, back-end and front-end, or more generally, data, logic and UX layers, but consists of microservices that are created around business capabilities, as displayed in Figure~\ref{fig:monovsmicro}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{myImages/monolithic-vs-microservices.png}
    \caption{Monolithic vs Microservice Architecture}
    \label{fig:monovsmicro}
\end{figure}

Second, the microservice architecture advocates for those services to be small.
It is not easy and in some cases inaccurate (e.g, in terms of LOC) to give an estimate of the magnitude of a service, however, a rule of thumb to keep in mind is, microservices should be small enough and not smaller \cite{newman}.
Each service should focus on one business functionality and do it well.
\\
Third, and the last major aspect that defines the microservice architecture is autonomy.
Each service in the microservice architecture is a separate entity, even to the degree that they are mostly designed, developed and deployed by separate teams.
Each team has staff that can together carry out full range of skills required for development, such as database, UX and project management.
\\
At this point, in order to summarize the mentioned major aspects of the microservice architecture and make the architecture more concrete by adding a bit more detail about the implementation, it is a good opportunity to take a look at the definition of the microservice architecture given by an influential software engineer in the field.
According to M. Fowler, the microservice architecture is, "in short, an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API.
These services are built around business capabilities and independently deployable by fully automated deployment machinery.
There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies." \cite{microdef}.
In the next section, each characteristic of the microservice architecture is explained in more detail.

\subsection{General Characteristics}
\label{subsec:chars}

\begin{itemize}
    \item Each microservice is developed by a small, cross-functional team.
    The team decides which programming language(s) and technology stack to choose to implement the microservice, and has their own CI/CD tools for testing, release and deployment.
    Each microservice is considered not just a project, but a product, and the development teams are responsible also for the deployment and production processes of their microservice, in the Amazon's notion of "you build it, you run it" \cite{youbuild}.
    
    \item Each microservice is a light-weight component that is independently deployable. In case of a change in a particular library, systems that have multiple libraries in a single process like a monolithic architecture has to redeploy entire application. Instead, in a same scenario, having multiple services facilitates redeploying only the changed service. Moreover, this kind of ease in deployment enables the system to be more fault-tolerant and scalable in a more dynamic way, as illustrated Figure~\ref{fig:scalability}.
    
    \begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{myImages/scalable.png}
    \caption{Scalability in Monolithic vs Microservice Apps}
    \label{fig:scalability}
\end{figure}

    \item Microservices communicate with each other by means of network calls, using well-defined APIs, and simple protocols like REST over HTTP. While some other architectures incorporate smart (and heavy-weight) messaging mechanisms, such as Enterprise Service Buses (ESB) that can do routing, transformation, choreography and some business logic, the microservice architecture opt for simple communication infrastructure that can do basic routing of messages. In short, they have smart endpoints and dumb pipes.

    \item Each microservice is a loosely-coupled business unit, that is responsible for a single part of the business capability.
    Each model of a microservice is designed on a Bounded Context, which is a part of Domain Driven Design technique \cite{boundedcontext}. Conceptual model of the real world entities are decentralized, meaning that the representation (name) and modeling (attributes) of same real world entities are distinct. Figure~\ref{fig:micromodel} illustrates an example bounded context design and highlights the different representation of the same entity in different microservices.
    
    \begin{figure}[H]
    \centering
    \subfloat[Same Concept as Different Model Entities in Different Microservices\label{fig:micromodel1}]{
        \includegraphics[scale=0.4]{myImages/micromodel1.png}
    }
    \quad
    \subfloat[Decomposing Traditional Data Models\label{fig:micromodel2}]{
        \includegraphics[scale=0.45]{myImages/micromodel2.png}
    }
    \caption{A Microservices Design Using Bound Context Model per Microservice}
    \label{fig:micromodel}
\end{figure}

    \item Just like the decentralized modeling, the persistence layer of the whole application is decentralized, in other words, each microservice and associated team is responsible for managing their own data. The team decides on which kind of database (SQL, NoSQL, graph, columnar, etc) they make use of, taking into consideration their own models and needs.

\end{itemize}

\subsection{Differences from Service Oriented Architecture}
\label{subsec:diff}

The profound idea of microservice architecture, which proposes splitting a system into loosely-coupled, reusable, specialized components is not new.
In the late 90's, Service Oriented Architecture (SOA) emerged as an enterprise-wide approach to software development of components that takes advantage of reusable software components, or services.
Similar to microservice architecture, each service is designed to execute business functions.
\\
Although the two architectures look quite identical at the first glance, they take different stands on the solutions of common problems in software architecture and therefore there are substantial differences between the two.
Listing the distinctions under three categories will help explain the difference.

\begin{itemize}
    \item Scope: SOA in general relates to enterprise-wide service exposure, while the microservice architecture has an application scope.
    The services are designed using common standards across development teams, aiming at re-usability and sharing of components, resources and data. On the other hand, microservices architecture embraces more relaxed governance approach, giving development teams more freedom of choice.
    Foregoing potential re-usability of code and data, microservice architecture prefers de-coupling of teams and services.
    
    \item Granularity: Having "re-usability across enterprise-wide system" in mind results in services that are fewer in number and larger in size in SOA. Each service typically handles more business functionality than microservices do. As for the persistence, SOA has a single data storage layer which is shared by all services, while each microservice has its own persistence mechanism, if needed for its specific business functionality. Although this results in data duplication in microservice architectures, it enables each microservice to be independent business unit in general \cite{soa_granularity}.
    Moreover, with respect to fine-grained microservices, coarse-grained services in SOA causes time-consuming deployment and less scalability.
    
    \item Communication: SOA makes use of ESB concept, which can handle, in addition to the communication between services using multiple protocols (RESTful API, SOAP, AMQP, MSMQ), management and configuration of services and even some business logic if needed \cite{soa_comm}.
    Having multiple capabilities like these can solve difficult integration problems in large scale systems, however, can possess the danger of single point of failure.
    In addition, the services across the enterprise frequently make synchronous calls, which can lead to latency issues and impact performance.
    To keep things simple, within an application scope, the microservice architecture prefers less elaborate and straightforward  messaging protocols such as HTTP, REST and Thrift.
    To provide communication and data synchronization across microservices, asynchronous communication models like event sourcing and pub/sub model are preferred.
\end{itemize}

\section{Design Patterns and Anti-Patterns in Microservices}
\label{sec:patterns}

Since its introduction by Netflix and discussions at workshops and software architecture conferences, the microservices architecture has gained quite a lot of popularity.
As the architecture is adopted more and more as time goes, legacy systems have been migrated and new projects have been developed utilizing the microservice architecture.
By sharing the experience after successful projects, similar to the evolution of design patterns in other paradigms, reusable solutions to commonly occurring problems have been identified and consequently design patterns in the microservice architecture showed up.
On the flip side, there has also been sub-optimal solutions during this period, resulting from several factors, some of which might be lack of experience, misunderstanding of the microservice architecture or just old habits from SOA.
In the same manner as design patterns, the anti-patterns of the microservice architecture has been identified by researchers and experienced engineers.
In the next two sections, the design patterns and anti-patterns that exist in microservice architectures are explored.

\subsection{Design Patterns}
\label{subsec:designpattern}

\subsubsection{API Gateway}
\label{subsubsec:api_gateway}

API gateway acts as a single point of entry for all clients as well as an edge service for exposing microservices to the outside world as managed APIs.
It sounds like a reverse proxy, but also has additional responsibilities like simple load-balancing, authentication, authorization, failure handling, auditing, protocol translations, and routing. An API Gateway should always be a highly-available and performant component, since it is the entry point to the entire system, as illustrated in Figure~\ref{fig:api_gateway}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{myImages/api_gateway.png}
    \caption{An example of an API Gateway pattern}
    \label{fig:api_gateway}
\end{figure}

The most common duties of an API gateway include:

\begin{itemize}
    \item Gateway Aggregation: Aggregate multiple client requests (usually HTTP requests) targeting multiple internal microservices into a single client request, reducing chattiness and latency between consumers and services.
    
    \item Gateway Offloading: Enable individual microservices to offload their shared service functionality to the API gateway level.
    Such cross-cutting functionalities include authentication, authorization, service discovery, fault tolerance mechanisms, QoS, load balancing, logging, analytics etc.
    
    \item Gateway Routing (layer 7 routing, usually HTTP requests): Route requests to the endpoints of internal microservices using a single endpoint, so that consumers don’t need to manage many separate endpoints.
\end{itemize}

Developers can choose from implementing their own API gateway, using an existing API gateway solution such as Kong or Express-Gateway, or in case of cloud deployment, choose from products such as Google Apigee, AWS API Gateway or Azure API Gateway.

\subsubsection{Service Mesh with Sidecar}
\label{subsubsec:service_mesh}

A service mesh is a configurable, low-latency infrastructure layer that is designed to tackle high volume of network-based inter-process communication among  application infrastructure services through APIs.
Service mesh pattern is in general implemented as an array of lightweight network proxies called sidecar, without needing the application to be aware of proxies \cite{li2019service}. The sidecar proxies in each service instance handles inter-process communication, monitoring and many other concerns.
Some aspects provided by this helper infrastructure include resiliency (fault tolerance, load balancing), service discovery, routing, observability, security, access control, communication protocol support and alike.
\\
The service mesh pattern is divided into two parts, namely, the control part and the data part, commonly referred as the control plane and the data plane. The control plane generates routing tables and deploy routing configuration to the proxies in the data plane. The actual forwarding of the network traffic is done by the proxies in the data plane, and for this reason, the data plane is also said to be the forwarding plane. Figure~\ref{fig:service_mesh} shows the diagram of an application with service mesh pattern, with the distinction of the control and data planes.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{myImages/service_mesh.png}
    \caption{An Application Architecture utilizing Service Mesh with Sidecar Proxy }
    \label{fig:service_mesh}
\end{figure}

Some of the advantages of making use of a service mesh are:

\begin{itemize}
    \item Logic Decoupling: Decoupling of network communications from microservice business logic code allows developers to focus on the business capabilities.
    
    \item Routing: Primitive routing capabilities, but no routing logic related to the business functionality of the service.
    
    \item Resiliency for inter-service communications: Circuit-breaking, retries and timeouts, fault injection, fault handling, load balancing and fail-over. 
    
    \item Service Discovery: Discovery of service endpoints through a dedicated service registry.
    
    \item Observability: Metrics, monitoring, distributed logging, distributed tracing.
    
    \item Security: Transport level security (TLS) and key management.
    
    \item Access Control: Simple blacklist and whitelist based access control.
    
    \item Deployment: Native support for containers, Docker and Kubernetes. Inter-service communication protocols: HTTP1.x, HTTP2, gRPC.
\end{itemize}

Implementations of the service mesh pattern include products such as Istio, Linkerd and Consul Connect.

\subsubsection{Service Registry and Discovery}
\label{subsubsec:srd}

In order for services to communicate, they expose a remote API at a particular location, specified by host and port number.
However, the number of service instances and locations change dynamically.
Scaling of services are done thanks to virtualization/containerization technologies and virtual machines and containers are usually assigned dynamic IP addresses.
For a service client to get a service, it needs to know the location of that particular service and this is done through service registry and discovery pattern.
When making a request, the client (of a service, it can be API gateway or another service), consults, directly or indirectly, to a service registry that keeps the up-to-date addresses of all service instances.
The clients of the service registry need to know the location(s) of the service registry instances, hence service registry instances must be deployed on fixed and well known IP addresses.
Although clients should cache data provided by the service registry, if the service registry fails that data will eventually become out of date. 
Consequently, the service registry must be highly available.

\begin{itemize}
    \item Service Registry: Service instances register themselves or a third party registers the service.
    A service registry might invoke a service instance’s health check API to verify that it is able to handle requests. Systems that provide service registry include middlewares such as Netflix Eureka, Apache Zookeeper; and service meshes such as Consul and Etcd. Some other systems such as Kubernetes, Marathon and AWS ELB have implicit service registry.
    
    \item Client-side Service Discovery: Query (of service registry) logic is built into the client.
    Spring Boot and Spring Cloud provides client-side service discovery, which is implemented by Netflix OSS (Open Source Software) components: service registry Eureka and HTTP client Ribbon that queries Eureka registry.
    
    \item Server-side Service Discovery: The client makes the request via a router that runs on a well known location.
    The router queries a service registry, which might be built into the router, and forwards the request to an available service instance.
    As an example, AWS Elastic Load Balancer acts as a router that load balances both external and internal traffic and also acts as a service registry.
    EC2 instances are registered with the ELB either explicitly via an API call or automatically as part of an auto-scaling group.
    Some clustering solutions such as Kubernetes and Marathon run a proxy (“service” in Kubernetes terminology) on each host that functions as a server-side discovery router.
    In order to access a service, a client connects to the local proxy using the port assigned to that service.
    The proxy then forwards the request to a service instance (or to controller such as ingress-nginx) running somewhere in the cluster.

\end{itemize}

\subsubsection{Backends For Frontends}
\label{subsubsec:bff}

Instead of using one common backend service for multiple clients, there are separate deployments of the same service with different configurations or implementations that can meet different UI requirements of different clients.
Each microservice that implements backends for frontends pattern provides an API, tailored specifically for one kind of client.
Because each backend is specific to one kind of client, it can be optimized for the interface the client uses.
As an example, while a microservice returns the detailed result of a query for the web application to use, another microservice with the same business capability, implemented with slightly different logic or configuration can return a concise version of the result to a mobile client.
As a result, each interface team has autonomy to control their own backend and does not need to rely on a centralized backend development team.

\subsubsection{Asynchronous Messaging}
\label{subsubsec:async_msg}

The distributed nature of microservices requires messaging mechanisms, ideally in a loosely-coupled manner.
The synchronous messaging results in tight run-time coupling, that is, both the client and the service need to be available during the whole messaging period.
To solve these issues and improve scalability, asynchronous messaging mechanisms are widely used in microservices architecture.
Solutions typically include light-weight event buses and message brokers.
Although an extra layer adds complexity, event buses and message brokers decrease run-time coupling by buffering messages, in other words, allowing the recipient to process messages when it becomes available.
Moreover, topics and content filtering can be used to create subsets of messages, delivered only to the interested parties.
With the help of built-in mechanisms of message brokers, different asynchronous messaging styles such as request/response, notification and publish/subscribe can be achieved.
Figure~\ref{fig:rabbitmq} illustrates an example diagram that includes RabbitMQ as a message broker, providing the publish/subscribe messaging manner.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{myImages/rabbitmq.png}
    \caption{RabbitMQ Message Broker with Pub/Sub Mechanism}
    \label{fig:rabbitmq}
\end{figure}

Implementations of message brokers include RabbitMQ and Apache Kafka.
The Key-Value store Redis can also be used as a message broker.
In addition, cloud providers offers message brokers and event buses with different capabilities, such as AWS SNS, AWS SQS, AWS Eventbridge, Azure Event Bus, Google Cloud Tasks and Google Cloud Pub/Sub.

\subsubsection{Database per Service}
\label{subsubsec:dps}

For the sake of loose-coupled services, each service’s persistent data is private to that service and accessible only via its API.
Even though keeping private tables or schema per service facilitates private data, having separate database instances per service also enables the deployment and scaling of services and the teams to be more independent.
By this means, each service can use the type of database that is best suited to its needs.
For example, a service that does text searches could use ElasticSearch, while
another service that manipulates a social graph could use Neo4j.
Although having a separate database server per service is aligned with loose coupling idea, it increases complexity in terms of implementation of transactions that span multiple services, since many NoSQL databases do not support conventional atomic distributed transactions, such as 2-Phase Commit \cite{twopc}.

\subsubsection{Saga}
\label{subsubsec:saga}

In order to solve the issue of implementing business transactions across multiple services, each multi-service transaction is implemented as a sequence of local transactions, which is called a saga.
If a local transaction fails because it violates a business rule then the saga executes a series of compensating transactions that undo the changes that were made by the preceding local transactions.
The two ways of implementing a saga pattern are:

\begin{itemize}
    \item Choreography-based Saga: A transaction is first targeted to a particular service (“order” service receives a POST request to "/orders").
    The service completes local transaction with its own database and emits an event to the event bus or a particular event channel (“order created” event in “order events” or a common channel).
    The service that subscribed to that kind of event sees the emitted event and does its own logic and local transaction to its own database and emits another event for any service that listens for that kind of event.
    If all steps are successful, the last service will let the first service know by emitting an event.
    Otherwise, if a failure occurs in a step, the service that could not get its job done (in terms of logic or infrastructure) fires a failure event for the previous step, so the services that have worked before this step can sequentially perform rollbacks.
    A diagram of choreography-based saga pattern is illustrated in Figure~\ref{fig:saga}.
    
    \begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{myImages/saga.jpeg}
    \caption{Choreography-based Saga Pattern}
    \label{fig:saga}
    \end{figure}
    
    \item Orchestration-based Saga: In this approach, unlike the above method, there is an orchestrator that manages the entire transaction.
    When a transaction order that is related to multiple services comes to the service, the service sends a command to the orchestrator.
    The orchestrator starts calling services to be called (directly or indirectly) and after a successful response, it calls the next one. Upon an answer that tells about a failure, the orchestrator then starts sending rollback messages to the previous services.
    With respect to the choreography approach, this method brings about scalability and single point of failure issues.

\end{itemize}

\subsubsection{API Composition}
\label{subsubsec:api_comp}

A simple way to implement queries that spans multiple services is API composition pattern
API composer service can take the query, then starts querying individual services that are related to the main query, join the responses and format the main query result to the client.
However, some queries would result in inefficient, in-memory joins of large datasets.

\subsubsection{Command Query Responsibility Segregation (CQRS)}
\label{subsubsec:cqrs}

Another way to respond to a query that covers numerous services is Command Query Segregation Pattern.
A service is wrapped around a view database that is a read-only replica that fulfils the query responsibility of the application.
The service keeps the database up-to-date by subscribing to domain events, published by the service that owns the data.
As the name suggests, separate services are responsible for the query (read) and command (write and any other logic) parts of the application.
Although it comes with potential complexity, code duplication and eventually consistent view nature, it supports multiple de-normalized views that are scalable and performant.

\subsubsection{Event Sourcing}
\label{subsubsec:event_sourcing}

A microservice typically needs to update its data and send or publish messages that conveys some information about the transaction or related business action.
For example, a service that participates in a saga needs to atomically update the database and sends messages or events.
If the database transaction is executed successfully, resulting messages must be sent and later, if the entity in the database rolls back to its previous state or changed again into a new state, related appropriate messages must be send to interested microservices.
In addition, the  ordering of messages must be preserved across multiple service instances that update the same aggregate.
\\
A good solution to this problem is to use event sourcing pattern.
Event sourcing persists the state of a business entity such as Order or a Customer as a sequence of state-changing events.
Whenever the state of a business entity changes, a new event is fired from the respective microservice, and stored in a database named as the event store, which can be an ACID-compliant database, a time-series database or a database server specifically implemented for event sourcing pattern, such as EventStore.
The most recent state of the application data is constructed by processing the events and storing the data in a materialised view that serves read-only queries.
Embracing the eventual consistency paradigm, the materialised view can be updated according to the constraints of the domain of the application, by finding the most recent snapshot of the application data and processing the persisted events that have occurred since that snapshot. Figure~\ref{fig:event_sourcing} illustrates the flow and storage of the events in a regular application that makes use of event sourcing pattern.

\begin{figure}[H]
\centering
\includegraphics[width=0.70\textwidth]{myImages/event-sourcing.png}
\caption{Event Sourcing Pattern}
\label{fig:event_sourcing}
\end{figure}

Moreover, event sourcing pattern makes it possible to implement temporal queries that determine the state of an entity at any point in time.
Append-only storage mechanism enables to see the actions taken related to a particular set of data, as well as assisting in testing and debugging \cite{event_sourcing_docs}.

\subsubsection{Service Instance per Virtual Machine}
\label{subsubsec:per_vm}

The microservices architecture promotes some ideas also for the deployment stage of the software lifecycle and these ideas are, as expected, built around loose-coupling paradigm.
The first of these patterns regarding the deployment process is service instance per virtual machine (VM) pattern.
Basically, in this method, each microservice is packaged as a VM image and deployed as an application running in its own VM, possibly with other VMs running on an hypervisor-based machine which is managed by Infrastructure-as-a-Service (IaaS) provider, such as AWS EC2, Google Compute Engine and Digital Ocean.
Packaging of a service as a VM image results in ease of scaling of services, which can also be automatically done by the IaaS provider based on the load.
Moreover, the details of the implementation of the service can be encapsulated in a VM image, therefore the dependence of the service technology over the physical host can be reduced.
With regard to the drawbacks, it is time-consuming for developers to create VM images and configure infrastructure components such as load balancers and firewalls.

\subsubsection{Service Instance per Container}
\label{subsubsec:per_container}

Another microservice pattern regarding the deployment aspect is service instance per container pattern.
Similar to packaging each service as a VM image, this pattern proposes packaging each service as a container image, in most cases, as a Docker image.
According to the official docs, Docker is an open platform for developing, shipping, and running applications, and provides the ability to package and run an application in a loosely isolated environment called a container \cite{docker_def}.
Docker containers provide many of the same advantages as VM images, however, due to the underlying virtualization method, Docker containers are much more lightweight with respect to VMs \cite{eder2016hypervisor}.
Rather than using a separate operating system, containers share a operating system, resulting in a significantly smaller size of each deployment.
Underneath, Docker make use of "linux kernel namespaces" and "control groups" to isolate resources of a single virtual or physical host (a single operating system in both cases) and allows Docker containers and services inside to consume resources of the host.
Being a more "micro" approach, containers make it easier for developers to package and share an application through "Docker Hub" and deploy a service as a container image, which is built with specifications taken from a "Dockerfile", to a private cloud or a Container-as-a-Service (CaaS) provider, such as Google Cloud Run or AWS Fargate.
Moreover, the overall resiliency of the application can be improved since it takes less time and effort to run a container with respect to a service with its own operating system.
For the sake of a clear understanding of the two virtualization methods mentioned, and how they differ from traditional deployment methods, the evolution of concepts are illustrated in Figure~\ref{fig:hypervisor_vs_container}. As a side note, it is interesting to see the same evolution towards fine-granularity, seen in application architecture from monoliths and SOA to microservices, also in software deployment approaches.

\begin{figure}[H]
\centering
\includegraphics[width=0.90\textwidth]{myImages/kubernetes_evo.png}
\caption{Comparison and evolution of traditional, hypervisor-based and container-based deployment}
\label{fig:hypervisor_vs_container}
\end{figure}

Microservices applications consist of tens or hundreds of microservices, and considering multiple instances for some services, the total number of service instances can be quite high.
In order for the advantages promised by the microservice architecture, supposing the adoption of container-based deployment, the cluster of containers must be properly instantiated, managed and observed.
To simplify the management of a cluster of containers, there are container orchestration platforms, such as Kubernetes, AWS Elastic Container Service, Docker Swarm and Mesosphere.
Among them, Kubernetes was initially developed by Google, open-sourced in 2014 and since then has been the most widely used container orchestration platform.
At this point, to see how containerization technology and orchestration platforms comes together to realize a microservice application, it is crucial to mention some capabilities of Kubernetes and challenges it tackles.
Some of the features of Kubernetes are:
\begin{itemize}
    \item Service Discovery and Load Balancing: Kubernetes exposes container via a DNS name or IP address to the cluster, can deploy an "ingress" component that can act as an API gateway, and can distribute network traffic between service instances if the load is high.
    
    \item Storage orchestration: Allows mounting (attaching, binding) of different storage options such as local storage and public cloud provider, to the containers.
    
    \item Automated rollouts and rollbacks: Enables developers to describe the desired state of the containers at hand and via a feed-back mechanism, tries to realize the desired state into the actual state of the cluster. In other words, "rolls out" changes in a progressive way and if something bad happens, "rolls back" changes to the previous stable state. It can create or remove containers and some kinds of Kubernetes objects such "Pods", "Deployments" and "Services" to carry out the task.
    
    \item Automatic bin packing: When provided with the information of how much CPU and memory a container needs, Kubernetes can figure out how to place containers to a set of nodes so that the resources are best utilized.
    
    \item Self-healing: Restarts containers that failed, and based on user-defined health-check, replaces or kills containers that do not respond. Moreover, it routes traffic to healthy instances until the failed container is ready to handle requests.
    
    \item Secret and Configuration Management: Stores and manages sensitive information such as passwords, OAuth access token and SSH keys. Without having to re-build container images, stores and updates application configuration such as environment variables.
\end{itemize}

In addition to stand-alone Kubernetes platform for on-premise solution, the cloud providers offer Kubernetes-as-a-Service options, such as Google Kubernetes Engine (GKE), AWS EKS and Azure AKS, that enables to run Kubernetes clusters on the cloud, by means of container images and Kubernetes config files.
\\
As a consequence of the capabilities explained above, and as also stated by researchers from IBM in a research paper \cite{jaramillo2016leveraging}, it is appropriate to say that Docker has been a disruptive technology which changed the way applications are developed and distributed.
Following the same concepts and ideas as microservice architectural paradigm itself, Docker is quite a good fit for building and deploying microservices.

\subsubsection{Serverless}
\label{subsubsec:serverless}

To deploy a microservice application, the services as source codes can be packaged (eg, as a ZIP file) and uploaded to the deployment infrastructure, which is an utility operated by a public cloud provider.
The infrastructure hides any concept of servers, resources, virtual machines and containers, it just takes the code and runs it.
Under the hood, it uses virtual machines and containers to isolate the services.
The client (of this service) is charged for each request based on the resources consumed.
This solution is very elastic in terms of scaling, however, it comes with significant constraints in the environment.
As an example, AWS Lambda limits the maximum time it can take for a microservice to serve a request to be fifteen minutes, making it unsuitable for microservices that need to execute for longer amount of time, such as data-processing batch jobs \cite{aws_lambda}.
Another important constraint in serverless pattern is, the microservices need to be "stateless", in other words, the microservice should not assume the existence of a particular data in its local file storage or memory to serve requests, instead, the state should be stored in persistence services such as AWS S3.
Constraints such as these allow small microservices to be instantiated quickly, making it suitable for developers to deploy not the entire microservice application but some particular microservices that are not called frequently enough to be deployed to its own host, reducing the insfrastructure costs.
Examples include AWS Lambda, Google Cloud Functions, Azure Functions.

\subsubsection{Health Check API}
\label{subsubsec:health_check_api}

Microservices, as any other software component, can crash or fail to serve the requests even if they still run.
During the times of unavailability, it is critical to notice those services that cannot carry out requests so that the requesting services do not wait unnecessarily, and instead, if there is another healthy instance of the failing service, are routed to those available instances.
Since the scope of a microservice is in general small, the availability status in terms of sufficient disk memory, connection to a database or a cache service or in general any other service it is dependant upon, can be coded or created from features of the framework being used.
As an example, the microservice can have an health check endpoint such as "/api/v1/health", and can respond to GET request with the status of the service described in a simple JSON file, possibly with HTTP status codes such as 200, 204, or 500, which stand for "OK", "No Content" and "Internal Server Error", respectively.
\\
In addition to health check mechanisms as code, the container orchestration platform Kubernetes offers health check methods that can be configured descriptively in Kubernetes configuration files by developers.
Kubernetes offers two kinds of health checking or "probing" options, named as liveness and readiness, and can carry out the health checks in periodic time intervals specified.
The first type, liveness, refers to whether a set of one or more containers, also knows as a "pod", is responsive or not.
In cases of a crash or a deadlock situation, restarting the pod can help make the service available again.
The second type, readiness, is used to decide if the service is ready to serve the requests, i.e., serves request only after loading data or configuration files or checking with services it depends on.
The health check API pattern, as seen from examples, is in fact helpful to detect and manage failures in microservices and hence the whole system, improving the resiliency of the application.

\subsubsection{Log Aggregator}
\label{subsubsec:log_aggregator}

As mentioned in the previous health check API pattern, from time to time, microservices may fail to serve the request and in some cases, it takes more than simple restarting the service to solve the issue.
Developers might need to take a look in the log files to find the exact cause of the problem.
In a microservice application, however, inspecting log files of a microservice by connecting to its host can be frustrating.
One reason is, there can be multiple instances of a microservice on different hosts, and it would be time-consuming to find the right host, especially if the services are scaled to new hosts automatically.
Another reason might be that, merely finding log files in most cases does not suffice to remove the bug, but trouble-shooting the microservices and comparing the logs from a chain of microservices is needed.
In order to ease the trouble-shooting process, log aggregator pattern can be utilized.
\\
Essentially, what log aggregator pattern proposes is, creating a central service and simply aggregating all log files from other microservices instances. Although this is simple idea, with some additions, the trouble-shooting process and developer experience can be significantly improved.
Through a configuration or log aggregator service, different logging types with various levels of detail can be specified to running microservices.
After creating a structured logging for all microservices with appropriate fields, to some extent, aggregated log files can be searchable.
Furthermore, advanced analyzing tools can be used to have more insights about the whole system.
As an example, ElasticSearch, Logstash and Kibana tools, also known as the "ELK" stack, are widely used for this purpose.
From microservices themselves or from a message broker, the logs are sent to data ingestion tool Logstash, and afterwards, ElasticSearch is used to analyze text or JSON data and Kibana is used to visualize the results to make the data more presentable for developers and data analysts.
Another example from a public cloud provider is AWS CloudWatch.
In addition to above-mentioned capabilities of ELK stack, CloudWatch can be configured to send alerting events or do some operational changes such as auto-scaling, if a particular word or a message occurs among the logs.

\subsubsection{Distributed Tracing}
\label{subsubsec:distributed_tracing}

In a microservice architected application, in contrary to a monolithic application, a request does not get handled by a single software component but rather by multiple microservices needed for that particular request.
From a system-wide point of view, a request, whether it is from an external UI agent or an internal microservice for a background job, results in an execution of a chain of microservices.
Naturally, this type of multi-call mechanism of microservices brings about complexity in terms of application development and performance monitoring.
For example, it would be helpful for developers to see which microservices are being called and which bounded domain contexts are being touched by a specific request.
Another exemplary scenario is that, some microservices might take more time to execute their tasks before calling the next microservice in the chain, so it would be beneficial to acquire how long it takes for microservices to complete their tasks so that the bottleneck of the system can be pinpointed and improved.
For these kind of tasks, distributed tracing pattern can be quite advantageous.
\\
In essence, distributed tracing pattern suggests assigning IDs to each external requests and passing it along with each call down the chain or path of execution, so that the path can be traced.
Each microservice is attached or instrumented with an agent that creates new spans for incoming requests and attaches context information required for identification to outgoing request.
Similar to log aggregator pattern, a central collector service receives trace data from agents, validates and stores data to be queried.
Finally, a query process queries the tracing database and shows the result of the query, possibly as a visualization using nodes, arrows or nested spans and related data.
Figure~\ref{fig:jaeger_trace} illustrates a detailed view of inter-service calls resulted from a GET request to an endpoint in frontend service, created by Jaeger, which is an open-source distributed tracing system.

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{myImages/trace-detail-ss.png}
\caption{Visualization of inter-service calls and timing data by Jaeger}
\label{fig:jaeger_trace}
\end{figure}

% learn how to cite CC license for the figure

As mentioned above, the distributed tracing pattern, similar to a service mesh, can be divided into two parts, an intrumentation or tracing part and the collection part.
Unsurprisingly, in order for a system to have distributed tracing capability, these two parts must be compatible, in other words, they must adhere to the same API specification.
In the open-source community, although there is no standardization yet, collective efforts such as OpenTracing tries to create a standardization of APIs, naming of concepts and shows tools such as Jaeger that complies with the OpenTracing standard.
Another major distributed tracing system is Zipkin, which supports distributed tracing integration with popular cloud frameworks such as Spring Cloud.

\subsubsection{Circuit Breaker}
\label{subsubsec:circuit_breaker}

From time to time, microservice instances may become unresponsive to other microservices, due to a high load that makes the service instance run out of resources, or a bug in the source code that makes the instance crash during run-time.
In a typical microservice application, the failure of microservice instances can be remedied by provisioning new ones, taking advantage of agile deployment capability thanks to fine-grained nature of the microservice architecture.
Nonetheless, in some cases, provisioning new instances of the failing microservice after the failure might not be good enough in terms of quality of service of the entire application.
As an example, if a call from the client side needs a service from a particular microservice and the request is routed to the failing microservice instance, the client would need to wait indefinitely, resulting in poor user experience.
In another and possibly more serious situation, if there are microservices that depend on the failing microservice instance, calls on the failing microservice might result in poor utilization of precious resources such as threads in other microservices, resulting in poor performance and possibly unresponsiveness in those microservice instance, effectively cascading the original failure to other connected components in the system.
The circuit breaker pattern, in effect, intends to block a failure in a microservice instance from spreading to other instances in the rest of the system.
The mechanism of doing so is basically wrapping calls to a service and inspecting the result of call in terms of success or failure.
If there are enough failures, the circuit breaker component cuts the connection logically, or "trips" as the electrical circuit breaker does.
After that, all attempts to invoke the failing instance immediately returns an error for a specified period of time, so that the clients of the service do not wait or consume resources in a futile waiting mode.
The circuit breaker pattern can be implemented in either the client or server side, or it can have its own microservice instance as a proxy between them \cite{montesi2016circuit}.
Figure~\ref{fig:circuit_breaker} shows the three states found in the circuit breaker pattern and the flow between them.

\begin{figure}[H]
\centering
\includegraphics[width=0.60\textwidth]{myImages/circuit_breaker.png}
\caption{State Diagram of Circuit Breaker Pattern}
\label{fig:circuit_breaker}
\end{figure}

\begin{itemize}
    \item Closed State: The closed state is the normal state of operation in which the requests are conveyed to the invoked service. The number of cases, in which there is a erroneous return value from the called service or no return at all, is counted, and when the threshold is reached, the circuit breaker trips to the open state.
    
    \item Open State: In the open state, the requests are not conveyed and instead an immediate failure message is given back to the caller service. By means of periodically polling the failing service and checking if there is a successful return, or just waiting for a specified amount of time, the half-open state is reached.
    
    \item Half-Open State: The half-open state acts as an intermediary step before making the circuit closed and granting all requests admission to the invoked service. In this state, only a limited number of requests are permitted to the target service, while others are returned with an immediate error message. In case any of the limited calls made to the service fails, the circuit goes back to the open state. Lastly, if the limited calls are handled and returned successfully by the previously failing instance, the circuit becomes closed again, returning to the normal operation with counters being reset.
\end{itemize}

Example libraries that implement the circuit breaker pattern include Netflix Hystrix and Resiliency4j for Java, Opossum for Node.js and Gobreaker for Go languages.

\subsection{Anti-Patterns}
\label{subsec:antipattern}

% write which papers are used as a guide for this section

\subsubsection{Wrong Cut}
\label{subsubsec:wrong_cut}

As mentioned previously, microservices are designed using bounded context method, that is, each microservice is designed to carry out tasks related to one small business capability.
One misconception for the separation of microservices is the construction of microservices in a layered fashion, as opposed to assigning one business capability per microservice.
Designing microservices so that each microservice takes care of a major task from a technical perspective of the whole application is in fact a bad habit from SOA.
To explain shortly and to not repeat the differences between SOA and microservices architectures, it is appropriate to say that, while designing microservices in a layered style like UI, logic and data increases re-usability of both code and data, it conflicts with the requirements needed for the microservice architecture to deliver its benefits.
The wrong cut anti-pattern causes deployments to be dependant on other services, breaks team independence and brings about high-coupling, since each business task would then require more microservices to be available.
To avoid this pattern, microservices should be designed from a business perspective and the ownership of logic and data to a development team should be preserved.

\subsubsection{Nano Microservice}
\label{subsubsec:nano_microservice}

Another anti-pattern due to bad design choices in terms of separation of microservices is the nano microservices anti-pattern.
Unlike the wrong cut anti-pattern, the nano microservice anti-pattern does not stem from a misconception of the design paradigm but the excess use of separation of business boundaries.
As the name suggests, there might be cases that the microservices are designed so small that they cannot carry out business capabilities in a more or less indepedent way.
Designing microservices unnecessarily small results in a larger number of microservices in the system, and increases communication overhead.
This anti-pattern can also manifests itself as a cyclic dependency among a set of microservices, hinting at the fact that they are designed to be dependant on each other's logic or data to serve an outside request.
To remedy this anti-pattern, the nano microservices can be re-designed around business capabilites, aimed at one business capability per microservice.
In the case of cyclic dependencies and frequent calls related to one business request, the microservices that take part in the related cluster or cycle can merged into a single microservice, yet taking into consideration that the new microservice does not become a megaservice.

\subsubsection{Mega Microservice}
\label{subsubsec:mega_microservice}

At the opposite end, there is the mega microservice anti-pattern, which means, designing one or more microservices in the system so that they can accomplish multiple business capabilities.
Having mega microservices in the application puts more work on the shoulders of the development team, and adding developers to the team leads to a situation that resembles a monolithic architecture.
It also results in additional difficulty in the deployment process, since in this case the part of system that changes in each deployment is larger, on contrary to one small microservice.
Again, it is important to design microservices in a way that each microservice performs one business capability.
Refactoring a mega microservice into a couple of microservices can help ease the deployment stage, and increase team independence.

\subsubsection{ESB Usage}
\label{subsubsec:esb_usage}

In the subsection \ref{subsec:diff}, the differences between the microservice and service-oriented architectures have been explained and particular roles each architectural paradigm assigns to the message broker component have been discussed.
Related to this difference, there is in fact an anti-pattern called ESB usage in the microservices world, that is based on the usage of ESB-like smart communication components in a microservice application.
The use of communication components that additionally takes care of service registry and discovery, transformation and some business logic contradicts with the "smart endpoints, dumb pipes" principle of the microservice architecture.
Rather than relying on the transformation of messages by an ESB, microservices should understand and handle different outlines of messages, register and discover services through a separate mechanism themselves.
Removing additional tasks such as these from the messaging component and using a lightweight message broker makes it easier to maintain the software and decreases the probability of a single point of failure case for the entire system.

\subsubsection{Hardcoded Endpoints}
\label{subsubsec:hardcoded_endpoints}

For a microservice to be able to make a request to another microservice, the requesting microservice need to know the location of the provider microservice.
The location of a microservice on the network is specificed via an IP address of its host and also a port number that is allocated for the process by the host in order to route network packets to the related process.
For that reason, to be able to communicate on the network, microservices need to know IP addresses and the port numbers of microservices that they need to make a request to.
In short, there are two main methods to handle this task.
The first solution is to delegate this task of knowing which microservice is where on the network to a separate microservice or an underlying infrastructure designed for microservice architectures, namely, using the service registry and discovery design pattern.
The second way, however, is the anti-pattern that is about to be explained, the hardcoded endpoints anti-pattern.
The solution of the second way, and the poor one, is explicitly stating the addresses of microservices through different mechanisms, such as writing in the source code or storing them in a configuration file or environment variable.
Although this method can be used during the development process, it makes it harder to scale the services for the production stage, since it would be necessary to update all other microservice instances to know about the location of a new microservice deployment.
In addition, using hardcoded endpoints undermines the benefits of an internal load balancer, if one is used to distribute some share of the traffic of requests to a recently instantiated microservice.
Taking into consideration the promises proposed by the microservice architecture, it is quite beneficial and in some cases necessary to employ design patterns such as service registry and discovery that shapes the system in a way that allows those promises to be delivered.

\subsubsection{No API Gateway}
\label{subsubsec:no_api_gateway}

Similar to the two previous anti-patterns, the no API gateway anti-pattern is in fact the absence of a microservice design pattern, namely API gateway pattern.
Without an API gateway, clients of the microservice application need to communicate directly with the microservice that are needed for a particular task.
The clients have to know the location of multiple microservices and might have to send multiple requests for the resources they need.
The auxiliary tasks such as authentication, without an API gateway, are needed to be done for each microservices.
Lastly, and probably the biggest difficulty of not having an API gateway is that the clients need to know how the application is structured, in other words, the names, locations and capabilities of microservices need to be conveyed to the client side.
For all these reasons, having an API gateway is of utmost importance for a microservice application to be able to communicate with the client in an effortless way.

\subsubsection{Shared Persistence}
\label{subsubsec:shared_persistence}

In section \ref{subsec:chars}, while listing the general characteristics of the microservice architecture, it is stated that each microservice in general has its own persistence layer, meaning that each microservice deals with storing and managing its own data in its own database instance.
The shared persistence anti-pattern, as the name suggests, stem from using the same database record (entity, row or document) or the same database instance to serve requests from multiple microservices.
It is important to note that, unlike many of the previous anti-patterns, the shared persistence anti-pattern contains a spectrum of choices that can be made to decide the extent how much flexibility is desired at the cost of duplication of data and less efficient use of infrastructure resources.
Besides having one database instance per service, microservices can share a single database instance, a database schema in a database and even tables in a database schema.
While the use of a single database maximizes re-usability, private database schemes and private database tables allow for various degrees of data privacy and ownership, at the expense of possible data duplication and redundancy in the database instance.
In some cases, the decision to share data among multiple microservices may seem reasonable to developers and architects, however, it is crucial to remember that shared persistence anti-pattern diminishes team independence in the sense that changes to schema and table design need to be coordinated, and increases run-time coupling, since all microservices need a particular database instance to be up and running to serve a single business capability.

\subsubsection{Shared Libraries}
\label{subsubsec:shared_libraries}

Similar to the shared persistence anti-pattern, the shared libraries is a common anti-pattern in the sense that developers opt for sharing logic instead of data for this particular anti-pattern.
Extracting common code to a library is one of the best practices in software development discipline, since it reduces development efforts by following "Don't repeat yourself" (DRY) principle.
In addition, if there are multiple microservices on the same host, they can share a run-time library so that the resources of the host are best utilized.
However, sharing both development and run-time libraries can be detrimental to the independent development principle of the microservice architecture.
Because of sharing libraries, a change in the shared library requires careful coordination among teams, slowing down development speed in the long term. Furthermore, if the change is not coordinated well enough, an update on a shared library may cause significant changes in other microservices, potentially breaking the entire application.
As a remedy, the run-time libraries can be refactored into a separate microservice, so that if there is a need to change the library, the change can be incrementally introduced, in other words, there can be separate instances that support both versions, or the library can a have versioned API.
For the shared development libraries, developers should prefer code duplication instead of risking wrong abstraction so that the development efforts remain stable in the future.

\subsubsection{No CI/CD Tools}
\label{subsubsec:no_cicd}

One of the main pillars of the microservice architecture is creating teams that develop microservices that handles one business capability.
The fine-grained decomposition allows teams to develop and maintain the microservice they own in an agile yet solid way.
To support the integration of development and operation tasks, teams are encouraged to use CI/CD tools, which allows for faster delivery without compromising software quality.
While it may seem easier to develop software without CI/CD tools at the first glance, the development and testing stage takes more time since a human agent needs to test the changed software part and possibly the whole software component, causing the time it takes to give feedback to developers to be longer.
On the other hand, having version control repositories for microservices, unit and integration tests in appropriate places, automated delivery mechanisms on successful commits and merges makes development faster and more under control.
Although the absence of CI/CD tools can also be disadvantageous for other software architectures, it is especially beneficial to use them in complex and modern architectures such as microservices so that the agility for microservice development can be achieved.

\subsubsection{Multiple Service Instances per Host}
\label{subsubsec:multiple_service_per_host}

For a microservices application, one of the deployment ways is deploying multiple microservice instances on a single virtual or physical host.
While this deployment option makes best use of resources of the underlying infrastructure, it severely harms the ease of scaling of services, since simply scaling a host results in all services that runs on the host to be scaled.
Moreover, different microservices may try to use different software components that runs on different OSs, or they can require different versions of the same dependency on the host machine, resulting in conflicting technologies and the need for a substantial amount of cooperation between teams during the development period.
In short, deploying multiple microservices on a single host is an anti-pattern and should be avoided in a microservice architecture.

\subsubsection{No API Versioning}
\label{subsubsec:no_api_versioning}

When a new version of a microservice is deployed, the developers may also decide to introduce a modified version of the former API, if it has been seen as a better fit for the newer version of the microservice.
In order not to break the communication between the altered microservice and other microservices, from time to time it is necessary for the altered microservice to support both the new and the old versions of its API, until other teams make changes required in their code that adopts the new API.
In cases such as these, API versioning can help identify the version of the API to be used between the client and the modified microservice.
The version of the API can be inserted in the URL path to be used by the client, or inserted as one of the custom headers in the HTTP request.
In addition, the degree of the change made to the API can be clarified to some extent, by using semantic versioning method.
The teams can coordinate and agree on a particular way of interpreting version numbers, or they also can make use of standization efforts such as SemVer.
In summary, utilizing API versioning is simple yet rewarding practice for microservices applications and not doing so may lead to inefficient communication efforts between teams.

\subsubsection{No Health Check}
\label{subsubsec:no_health_check}

Microservice applications may contain dozens of microservice instances, and for this reason, a failure or a crash in a microservice instance does not necessarily lead to an entire system-wide breakdown, making the failure hard to notice.
Not implementing a health check API endpoint in microservices or utilizing the related health check feature of the underlying container orchestration platform such as the one from Kubernetes is not just a trade-off but an anti-pattern in microservice architectures.
Specifying periodic health check in the orchestration platform or adding a couple of simple health check logic into request handling code of microservices is a valuable investment that can help monitor the whole application, making it easier to find and fix the service instance down or route requests to up-and-running instances until the problem is solved.

\subsubsection{Local Logging}
\label{subsubsec:local_logging}

Another bad practice that makes microservice applications less transparent to the developers is local logging anti-pattern.
Although implementing a distributed logging service is not trivial, say, compared to adding a health check endpoint, because of the significant disadvantages it causes in applications with large number of microservices, solely storing logs locally per microservice basis constitutes an anti-pattern.
Without a log aggregation mechanism, analyzing the state of the application requires more time and unimaginable effort in cases where the logs are larger in size and number.
In consequence, having a distributed logging structure in staging and production environments reduces trouble-shooting efforts and helps with monitoring processes.

\chapter{Research Methodology}
\label{ch:research_method}%

In this chapter, the work conducted is described.
First, the research questions constructed for the study are introduced and in the next section, the methodology used to answer those research questions are explained.

\section{Research Questions}
\label{sec:research_questions}

For the scope of this study, the following two research questions have been established.

\begin{itemize}
    \item \textbf{RQ1}: Is there a consistent categorization or classification of design patterns and anti-patterns of microservice architectures in the academia?
    If not, what could be an alternative way to structure those design patterns and anti-patterns?
    
    \item \textbf{RQ2}: Are the design patterns and anti-patterns of microservice architectures also reflected in the popular microservice projects in the open source community?
    Which design patterns and anti-patterns exist in those prominent projects?
\end{itemize}

Through these two research questions, the goal of this study is to see the level of sophistication and finesse in which the microservice design patterns and anti-patterns are categorised in the academia and to validate the occurrence of microservice design patterns and anti-patterns mentioned in the academia on a limited set of open source microservice projects.

\section{Adopted Methodology}
\label{sec:adopted_method}

To answer first research question, the following steps have been adopted.

\begin{itemize}
    \item In the first step, a literature review on electronic databases has been conducted.

    \item item 2
\end{itemize}

\chapter{Results}
\label{ch:results}%

In this chapter, the results of the research process are described.
The first two section reports on the findings of the research related to the two research question, with the intention of giving accurate answers to the research questions.
Next, in the light of the experience and data collected during the research process, additional comments have been made about the microservice design patterns and anti-patterns in the discussion of findings section.

\section{Classification of Patterns}
\label{subsec:classification_result}

In order to find out whether there exists a consistent classification of microservice design patterns and anti-patterns, research papers about the topic have been investigated.
Digital libraries such as IEEE Explore, ACM Digital Library, Springer, Scopus, and the literature research tool, Google Scholar, have been consulted.
The keywords used in the search queries made to the libraries included "microservice pattern", "microservice pattern classification", "microservice anti-pattern" and "microservice anti-pattern classification".
It has been detected that, while there exists many studies regarding one or more design patterns or anti-patterns of microservice architectures, few studies approach to the topic from holistic point of view, in other words, mention or conduct a study involving different kinds of design patterns and anti-patterns of microservice architectures.
After initial review of the studies, few more studies have been added through snowballing technique, and from this extended set, studies that do not contain a classification or grouping of patterns and anti-patterns have been eliminated.
The remaining set of primary studies used to answer the first research question are listed in Table~\ref{table:studies}. 

\begin{table}[H]
\centering 
    \begin{tabular}{|l p{33em} l|}
    \hline
    \rowcolor{bluepoli!40}
    \textbf{ID} & \textbf{Title} & \textbf{Format}\T\B \\
    \hline \hline
    P1 & A systematic mapping study in microservice architecture \cite{7796008} & Conference\T\B\\
    \hline
    P2 & Architecting with microservices: a systematic mapping study \cite{DIFRANCESCO201977} & Journal\T\B\\
    \hline
    P3 & Architectural patterns for microservices: a systematic mapping study \cite{TaibiD2018APfM} & Conference\T\B\\
    \hline
    P4 & Deployment and communication patterns in microservice architectures: a systematic literature review \cite{KARABEYAKSAKALLI2021111014} & Journal\T\B\\
    \hline
    P5 & Patterns related to microservice architecture: a multivocal literature review \cite{valdivia} & Journal\T\B\\
    \hline
    P6 & Microservices: a systematic mapping study \cite{10.5220/0005785501370146} & Conference\T\B\\
    \hline
    P7 & A pattern language for scalable microservices-based systems \cite{10.1145/3241403.3241429} & Conference\T\B\\
    \hline
    P8 & Actual use of architectural patterns in microservices-based open source projects \cite{8719492} & Conference\T\B\\
    \hline
    P9 & Towards a taxonomy of microservices architectures \cite{10.1007/978-3-319-74781-1_15} & Conference\T\B\\
    \hline
    P10 & Quality attributes in patterns related to microservice architecture: a systematic literature review \cite{9105640} & Conference\T\B\\
    \hline
    P11 & Microservices anti-patterns: a taxonomy \cite{Taibi2020} & Book chapter\T\B\\
    \hline
    P12 & On the study of microservices antipatterns: a catalog proposal \cite{10.1145/3424771.3424812} & Conference\T\B\\
    \hline
    P13 & Towards a collaborative repository for the documentation of service-based antipatterns and bad smells \cite{8712355} & Conference\T\B\\
    \hline
    P14 & Quality assurance for microservice architectures \cite{9522227} & Conference\T\B\\
    \hline
    \end{tabular}
    \\[10pt]
    \caption{Primary studies that contain classification of patterns or anti-patterns}
    \label{table:studies}
\end{table}

\section{Patterns and Anti-Patterns in Microservice Projects}
\label{subsec:pattern_result}

\section{Discussion of Findings}
\label{sec:discussion}

number of studies of pattern > studies of anti-patterns
aksakalli2021deployment
\chapter{Conclusion}
\label{ch:conclusion}%

%-------------------------------------------------------------------------
%	BIBLIOGRAPHY
%-------------------------------------------------------------------------

\addtocontents{toc}{\vspace{2em}} % Add a gap in the Contents, for aesthetics
\bibliography{myThesisBib}

%-------------------------------------------------------------------------
%	APPENDICES
%-------------------------------------------------------------------------

\cleardoublepage
\addtocontents{toc}{\vspace{2em}} % Add a gap in the Contents, for aesthetics
\appendix
\chapter{Appendix A}
If you need to include an appendix to support the research in your thesis, you can place it at the end of the manuscript.
An appendix contains supplementary material (figures, tables, data, codes, mathematical proofs, surveys, \dots)
which supplement the main results contained in the previous chapters.

% LIST OF FIGURES
\listoffigures

% LIST OF TABLES
\listoftables

% LIST OF ABBREVIATIONS
% Write out the List of Symbols in this page
\chapter*{List of Abbreviations}
\begin{table}[H]
    \centering
    \begin{tabular}{ll}
        \textbf{Abbreviation} & \textbf{Description} \\\hline\\[-9px]
        AMQP & Advanced Messaging Queuing Protocol \\[2px]
        API & Application Programming Interface \\[2px]
        BC & Bounded Context \\[2px]
        CI/CD & Continuous Integration / Continuous Delivery \\[2px]
        CaaS & Container-as-a-Service \\[2px]
        CQRS & Command Query Responsibility Segregation \\[2px]
        DDD & Domain Driven Design \\[2px]
        DRY & Don't Repeat Yourself \\[2px]
        ESB & Enterprise Service Bus \\[2px]
        HTTP & Hypertext Transfer Protocol \\[2px]
        IaaS & Infrastructure-as-a-Service \\[2px]
        JSON & Javascript Object Notation \\[2px]
        LOC & Lines of Code \\[2px]
        MSMQ & Microsoft Messaging Queuing \\[2px]
        NoSQL & Not-Only-SQL, to refer to different kinds of non-relational databases \\[2px]
        QoS & Quality of Service \\[2px]
        REST & Representational State Transfer \\[2px]
        RESTful API & an API that adheres to REST principles \\[2px]
        SOA & Service Oriented Architecture \\[2px]
        SOAP & Simple Object Access Protocol \\[2px]
        SQL & Structured Query Language \\[2px]
        SSH & Secure Shell \\[2px]
        TLS & Transport Layer Security \\[2px]
        UI & User Interface \\[2px]
        UX & User Experience \\[2px]
        VM & Virtual Machine \\[2px]
    \end{tabular}
\end{table}

% ACKNOWLEDGEMENTS
\chapter*{Acknowledgements}
Here you might want to acknowledge someone.

\cleardoublepage

\end{document}
